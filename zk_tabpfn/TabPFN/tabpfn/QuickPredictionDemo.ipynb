{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use TabPFN for tabular prediction with a scikit learn wrapper.\n",
    "\n",
    "classifier = TabPFNClassifier(device='cpu')\n",
    "classifier.fit(train_xs, train_ys)\n",
    "prediction_ = classifier.predict(test_xs)\n",
    "\n",
    "The fit function does not perform any computations, but only saves the training data. Computations are only done at inference time, when calling predict.\n",
    "Note that the presaved models were trained for up to 100 features, 10 classes and 1000 samples. While the model does not have a hard bound on the number of samples, the features and classes are restricted and larger sizes lead to an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%autoreload all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from scripts.model_builder import get_default_spec, save_model, load_model_only_inference\n",
    "from scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, TabPFNClassifier\n",
    "# from scripts.differentiable_pfn_evaluation import eval_model, eval_model_range\n",
    "\n",
    "from datasets import load_openml_list, open_cc_dids, open_cc_valid_dids, test_dids_classification\n",
    "\n",
    "from scripts import tabular_metrics\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from functools import partial\n",
    "import tabpfn.encoders as encoders\n",
    "\n",
    "from transformer import TransformerModel\n",
    "\n",
    "from tabpfn.utils import get_uniform_single_eval_pos_sampler\n",
    "import torch\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerModel??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_only_inference(path, filename, device):\n",
    "    \"\"\"\n",
    "    Loads a saved model from the specified position. This function only restores inference capabilities and\n",
    "    cannot be used for further training.\n",
    "    \"\"\"\n",
    "\n",
    "    model_state, optimizer_state, config_sample = torch.load(os.path.join(path, filename), map_location='cpu')\n",
    "\n",
    "    if (('nan_prob_no_reason' in config_sample and config_sample['nan_prob_no_reason'] > 0.0) or\n",
    "        ('nan_prob_a_reason' in config_sample and config_sample['nan_prob_a_reason'] > 0.0) or\n",
    "        ('nan_prob_unknown_reason' in config_sample and config_sample['nan_prob_unknown_reason'] > 0.0)):\n",
    "        encoder = encoders.NanHandlingEncoder\n",
    "    else:\n",
    "        encoder = partial(encoders.Linear, replace_nan_by_zero=True)\n",
    "\n",
    "    n_out = config_sample['max_num_classes']\n",
    "\n",
    "    device = device if torch.cuda.is_available() else 'cpu:0'\n",
    "    encoder = encoder(config_sample['num_features'], config_sample['emsize'])\n",
    "\n",
    "    nhid = config_sample['emsize'] * config_sample['nhid_factor']\n",
    "    y_encoder_generator = encoders.get_Canonical(config_sample['max_num_classes']) \\\n",
    "        if config_sample.get('canonical_y_encoder', False) else encoders.Linear\n",
    "\n",
    "    assert config_sample['max_num_classes'] > 2\n",
    "    loss = torch.nn.CrossEntropyLoss(reduction='none', weight=torch.ones(int(config_sample['max_num_classes'])))\n",
    "    with torch.no_grad():\n",
    "        model = TransformerModel(encoder, n_out, config_sample['emsize'], config_sample['nhead'], nhid,\n",
    "                                config_sample['nlayers'], y_encoder=y_encoder_generator(1, config_sample['emsize']),\n",
    "                                dropout=config_sample['dropout'],\n",
    "                                # efficient_eval_masking=config_sample['efficient_eval_masking']\n",
    "                                full_attention=True,\n",
    "                                num_global_att_tokens=None,\n",
    "                                )\n",
    "\n",
    "        # print(f\"Using a Transformer with {sum(p.numel() for p in model.parameters()) / 1000 / 1000:.{2}f} M parameters\")\n",
    "\n",
    "        model.criterion = loss\n",
    "        module_prefix = 'module.'\n",
    "        model_state = {k.replace(module_prefix, ''): v for k, v in model_state.items()}\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        return model # no loss measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../tabpfn/models_diff/'\n",
    "filename = 'prior_diff_real_checkpoint_n_0_epoch_42.cpkt'\n",
    "model = load_model_only_inference(path,filename,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  torch.randn(625, 3, 100)\n",
    "y = torch.randn(312,3)\n",
    "dummy = {'src': (x,y)}\n",
    "model.forward(**dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onnx(model, onnx_file_path):\n",
    "    x =  torch.randn(625, 3, 100)\n",
    "    y = torch.randn(312,3)\n",
    "    dummy_input = {'src': (x,y),'single_eval_pos':312}\n",
    "    torch.onnx.export(model, dummy_input, onnx_file_path,\n",
    "                      export_params=True, opset_version=13, do_constant_folding=True)\n",
    "\n",
    "    print(f\"Model has been converted to ONNX and saved as {onnx_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_onnx(model, 'full_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.y_encoder.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_input = torch.randn(512,1)\n",
    "torch.onnx.export(model.y_encoder,torch_input,'y_encoder.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(model.transformer_encoder.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_enc_0 = model.transformer_encoder._modules['layers'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_enc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_enc_0.self_attn.out_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.y_encoder.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "new_module = nn.Linear(1,512)\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_module.weight.copy_(model.y_encoder.weight)\n",
    "\n",
    "torch_input = torch.randn(512,1)\n",
    "torch.onnx.export(new_module,torch_input,'y_encoder.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_input = torch.randn(512,512)\n",
    "torch.onnx.export(model.transformer_encoder.layers, torch_input, 't_enc_all.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for module_name in model._modules:\n",
    "#     module = getattr(model,module_name)\n",
    "#     torch_input = torch.randn(module.out_features,module.in_features)\n",
    "#     torch.onnx.export(model.module, torch_input,f'{module}.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class MyModel(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(MyModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "#         self.fc2 = nn.Linear(120, 512)\n",
    "#         self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "#         x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "# torch_model = MyModel()\n",
    "# torch_input = torch.randn(1, 1, 32, 32)\n",
    "# torch.onnx.export(torch_model, torch_input, 'model2.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = '.'\n",
    "max_samples = 10000\n",
    "bptt = 10000\n",
    "\n",
    "cc_test_datasets_multiclass, cc_test_datasets_multiclass_df = load_openml_list(open_cc_dids, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = max_samples, num_feats=100, return_capped=True)\n",
    "cc_valid_datasets_multiclass, cc_valid_datasets_multiclass_df = load_openml_list(open_cc_valid_dids, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = max_samples, num_feats=100, return_capped=True)\n",
    "\n",
    "# Loading longer OpenML Datasets for generalization experiments (optional)\n",
    "# test_datasets_multiclass, test_datasets_multiclass_df = load_openml_list(test_dids_classification, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = 10000, num_feats=100, return_capped=True)\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(cc_valid_datasets_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(selector, task_type, suite='cc'):\n",
    "    if task_type == 'binary':\n",
    "        ds = valid_datasets_binary if selector == 'valid' else test_datasets_binary\n",
    "    else:\n",
    "        if suite == 'openml':\n",
    "            ds = valid_datasets_multiclass if selector == 'valid' else test_datasets_multiclass\n",
    "        elif suite == 'cc':\n",
    "            ds = cc_valid_datasets_multiclass if selector == 'valid' else cc_test_datasets_multiclass\n",
    "        else:\n",
    "            raise Exception(\"Unknown suite\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string, longer, task_type = '', 1, 'multiclass'\n",
    "eval_positions = [1000]\n",
    "bptt = 2000\n",
    "    \n",
    "test_datasets, valid_datasets = get_datasets('test', task_type, suite='cc'), get_datasets('valid', task_type, suite='cc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Run on a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, test_datasets[i][0]) for i in range(len(test_datasets))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset_index = 0 # Index of the dataset to predict\n",
    "ds = test_datasets[evaluation_dataset_index]\n",
    "print(f'Evaluation dataset name: {ds[0]} shape {ds[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = ds[1].clone(), ds[2].clone()\n",
    "eval_position = xs.shape[0] // 2\n",
    "train_xs, train_ys = xs[0:eval_position], ys[0:eval_position]\n",
    "test_xs, test_ys = xs[eval_position:], ys[eval_position:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintain this interface - override the model loading to instead use Giza/Onnx \n",
    "# pass Giza models to transformer_predict instead of self.model[2]\n",
    "classifier = TabPFNClassifier(device='cpu', only_inference=True)\n",
    "\n",
    "\n",
    "# make fit() a task\n",
    "classifier.fit(train_xs, train_ys)\n",
    "\n",
    "# modify transformer_predict to use Giza Model model predict instead of checkpoint(predict,\n",
    "# line 360 in predict - use GizaModel and predict interface instead of model()\n",
    "# replace model() with a worflow function that chains together all the GizaModels\n",
    "# make dataset only one batch\n",
    "\n",
    "# make predict_proba a task\n",
    "prediction_ = classifier.predict_proba(test_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# try porting over original tabpfn as a giza action! - make sure everything but onnx works\n",
    "# save out totally pre-processed batch train and test\n",
    "# port over TabPFN dependencies into the zk_tabpfn repo. (reproduce)\n",
    "\n",
    "# test model execution using onnx format (test with just linear layer with dummy input, then with preprocessed real data)\n",
    "# load in all the model layers and chain their outputs\n",
    "# use final prediction logic from Tabpfn\n",
    "\n",
    "# figure out how eval_pos is used by the model forward pass! \n",
    "# should the input_feed pass exal_xs, eval_ys, eval_pos ??\n",
    "\n",
    "# try the weight copy hack to get full transpilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model[2].transformer_encoder.layers._modules['0']._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model[2].transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ce = tabular_metrics.auc_metric(test_ys, prediction_), tabular_metrics.cross_entropy(test_ys, prediction_)\n",
    "'AUC', float(roc), 'Cross Entropy', float(ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Run on all datasets\n",
    "This section runs a differentiable hyperparameter tuning run and saves the results to a results file, which can be inserted in TabularEval.ipynb to compare to other baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_positions=[1000]\n",
    "bptt=2000\n",
    "\n",
    "N_models = 3\n",
    "models_per_block = 1\n",
    "\n",
    "eval_addition = 'user_run'\n",
    "device = 'cpu'\n",
    "\n",
    "eval_model_range(i_range=[0], e=-1\n",
    "                          , valid_datasets=[]#cc_valid_datasets_multiclass\n",
    "                          , test_datasets=cc_test_datasets_multiclass\n",
    "                          , train_datasets=[]\n",
    "                          , eval_positions_test=eval_positions\n",
    "                          , bptt_test=bptt\n",
    "                          , add_name=model_string\n",
    "                          , base_path=base_path\n",
    "                          , selection_metric='auc'\n",
    "                          , best_grad_steps=0\n",
    "                          , eval_addition=eval_addition\n",
    "                          , N_ensemble_configurations_list = [32]\n",
    "                          , device=device)#range(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run generalization experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading longer OpenML Datasets for generalization experiments (optional)\n",
    "test_datasets_multiclass, test_datasets_multiclass_df = load_openml_list(test_dids_classification, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = 10000, num_feats=100, return_capped=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets_longer_generalization = [ds for ds in test_datasets_multiclass if ds[1].shape[0] >= 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gen(classifier_key, split):\n",
    "    ces = []\n",
    "    for k in tqdm(range(0, len(test_datasets_longer_generalization))):\n",
    "        x, y = test_datasets_longer_generalization[k][1], test_datasets_longer_generalization[k][2].numpy()\n",
    "        x = normalize_data(x).numpy()\n",
    "        x[np.isnan(x)] = 0.0\n",
    "        print(x.shape[0])\n",
    "        \n",
    "        if x.shape[0] < 10000:\n",
    "            continue\n",
    "        if len(np.unique(y)) > 2:\n",
    "            continue\n",
    "\n",
    "        for bptt_ in [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000]:\n",
    "            bptt_ = bptt_ // 2\n",
    "            #model = classifier_dict[classifier_key]\n",
    "            x_, y_ = x.copy(), y.copy()\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x_, y_, test_size=0.5, random_state=split)\n",
    "            x_train, y_train = x_train[0:bptt_], y_train[0:bptt_]\n",
    "            model.fit(x_train, y_train) # ranking[0:j]\n",
    "            pred = model.predict_proba(x_test) # ranking[0:j]\n",
    "            ce = tabular_metrics.auc_metric(y_test, pred)\n",
    "            ces += [{'bptt': bptt_, 'k': k, 'm': float(ce), 'method': classifier_key, 'split': split}]\n",
    "            print(x_train.shape, ce)\n",
    "    with open(f'generalization_{classifier_key}_{split}.obj',\"wb\") as fh:\n",
    "        pickle.dump(ces,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen('tabpfn', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ces = []\n",
    "for classifier_key in classifier_dict:\n",
    "    for split in range(0,5):\n",
    "        try:\n",
    "            with open(f'generalization_{classifier_key}_{split}.obj',\"rb\") as fh:\n",
    "                ces += pickle.load(fh)\n",
    "        except:\n",
    "            pass\n",
    "df = pd.DataFrame(ces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['bptt', 'split', 'method']).mean().reset_index()\n",
    "fig, ax = plt.subplots(1,1, figsize=(8, 6)) # , sharey=True\n",
    "\n",
    "colors = iter(sns.color_palette(\"tab10\"))\n",
    "for classifier_key in ['tabpfn']:#df.method.unique():\n",
    "    c = next(colors)\n",
    "    sns.lineplot(x='bptt', y='m', data=df[df.method==classifier_key], label=relabeler[classifier_key], color=c, ax = ax)\n",
    "    #ax.text(x = df[df.method==classifier_key].iloc[50].bptt, # x-coordinate position of data label\n",
    "    # y = df[df.method==classifier_key].iloc[50].m, # y-coordinate position of data label, adjusted to be 150 below the data point\n",
    "    # s = classifier_key, # data label, formatted to ignore decimals\n",
    "    # color = c, size=12) # set colour of line\n",
    "    \n",
    "ax.get_legend().remove()\n",
    "ax.set(xlabel='Number of training samples')\n",
    "ax.set(ylabel='ROC AUC')\n",
    "plt.axvline(x=1024, linestyle='dashed', color='red')\n",
    "plt.ylim((0.73,0.79))\n",
    "plt.xlim((250,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
